{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer Learnign Model Keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras import backend as K\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 32, 32\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'C:/Users/dm12505/Desktop/val'\n",
    "validation_data_dir = 'C:/Users/dm12505/Desktop/val'\n",
    "nb_train_samples = 6\n",
    "nb_validation_samples = 6\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "test_dir = 'C:/Users/dm12505/Desktop/test1'\n",
    "nb_test_samples = 6\n",
    "test_batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# reading in image data from training and validation steps \n",
    "\n",
    "# use ImageDataGenerator to normalize/augment \n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# use flow_from_directory method to resize/pre-process \n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "#use model predict to create bottleneck weights from VGG16 & save to .npy file\n",
    "\n",
    "bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "bottleneck_features_test = model.predict_generator(\n",
    "        generator, nb_test_samples // batch_size)\n",
    "np.save(open('bottleneck_features_test.npy', 'wb'), bottleneck_features_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and create labels in sequential order\n",
    "\n",
    "# cats 0; dogs 1 \n",
    "\n",
    "train_data = np.load(open('bottleneck_features_train.npy','rb'))\n",
    "train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy','rb'))\n",
    "validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "test_data = np.load(open('bottleneck_features_test.npy','rb'))\n",
    "test_labels = np.array([0] * (nb_test_samples // 2) + [1] * (nb_test_samples // 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1, 1, 512)\n",
      "(6,)\n",
      "(6, 1, 1, 512)\n",
      "(6,)\n",
      "(6, 1, 1, 512)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(validation_data.shape)\n",
    "print(validation_labels.shape)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 131,585\n",
      "Trainable params: 131,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create dense fully connected model to add to base pre-configured model \n",
    "# inputs from trained bottled features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples, validate on 6 samples\n",
      "Epoch 1/50\n",
      " - 0s - loss: 0.7627 - acc: 0.8333 - val_loss: 0.4969 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49692, saving model to model.weights.best.hdf5\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.5111 - acc: 0.8333 - val_loss: 0.3463 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49692 to 0.34630, saving model to model.weights.best.hdf5\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.3923 - acc: 0.8333 - val_loss: 0.2560 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34630 to 0.25596, saving model to model.weights.best.hdf5\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.2583 - acc: 1.0000 - val_loss: 0.1957 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.25596 to 0.19566, saving model to model.weights.best.hdf5\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.2482 - acc: 1.0000 - val_loss: 0.1523 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.19566 to 0.15231, saving model to model.weights.best.hdf5\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.1526 - acc: 1.0000 - val_loss: 0.1144 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15231 to 0.11445, saving model to model.weights.best.hdf5\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.1207 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.11445 to 0.09073, saving model to model.weights.best.hdf5\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.1001 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09073 to 0.07505, saving model to model.weights.best.hdf5\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0569 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07505 to 0.06537, saving model to model.weights.best.hdf5\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0526 - acc: 1.0000 - val_loss: 0.0585 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.06537 to 0.05846, saving model to model.weights.best.hdf5\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0412 - acc: 1.0000 - val_loss: 0.0490 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.05846 to 0.04895, saving model to model.weights.best.hdf5\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0330 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.04895 to 0.04119, saving model to model.weights.best.hdf5\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.0739 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.04119 to 0.03473, saving model to model.weights.best.hdf5\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.0626 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03473 to 0.02947, saving model to model.weights.best.hdf5\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.0224 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02947 to 0.02617, saving model to model.weights.best.hdf5\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0357 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02617 to 0.02342, saving model to model.weights.best.hdf5\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0406 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02342 to 0.02131, saving model to model.weights.best.hdf5\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0283 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02131 to 0.01828, saving model to model.weights.best.hdf5\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0190 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01828 to 0.01596, saving model to model.weights.best.hdf5\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0243 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01596 to 0.01429, saving model to model.weights.best.hdf5\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01429 to 0.01311, saving model to model.weights.best.hdf5\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01311 to 0.01212, saving model to model.weights.best.hdf5\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01212 to 0.01139, saving model to model.weights.best.hdf5\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01139 to 0.01064, saving model to model.weights.best.hdf5\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01064 to 0.01000, saving model to model.weights.best.hdf5\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01000 to 0.00932, saving model to model.weights.best.hdf5\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00932 to 0.00858, saving model to model.weights.best.hdf5\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00858 to 0.00801, saving model to model.weights.best.hdf5\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00801 to 0.00751, saving model to model.weights.best.hdf5\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0232 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00751 to 0.00676, saving model to model.weights.best.hdf5\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00676 to 0.00623, saving model to model.weights.best.hdf5\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00623 to 0.00592, saving model to model.weights.best.hdf5\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00592 to 0.00565, saving model to model.weights.best.hdf5\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00565 to 0.00537, saving model to model.weights.best.hdf5\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00537 to 0.00509, saving model to model.weights.best.hdf5\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00509 to 0.00482, saving model to model.weights.best.hdf5\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00482 to 0.00461, saving model to model.weights.best.hdf5\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00461 to 0.00436, saving model to model.weights.best.hdf5\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00436 to 0.00415, saving model to model.weights.best.hdf5\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00415 to 0.00390, saving model to model.weights.best.hdf5\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00390 to 0.00377, saving model to model.weights.best.hdf5\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00377 to 0.00352, saving model to model.weights.best.hdf5\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00352 to 0.00332, saving model to model.weights.best.hdf5\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00332 to 0.00311, saving model to model.weights.best.hdf5\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00311 to 0.00298, saving model to model.weights.best.hdf5\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00046: val_loss improved from 0.00298 to 0.00285, saving model to model.weights.best.hdf5\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00285 to 0.00271, saving model to model.weights.best.hdf5\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00271 to 0.00258, saving model to model.weights.best.hdf5\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00258 to 0.00248, saving model to model.weights.best.hdf5\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00248 to 0.00239, saving model to model.weights.best.hdf5\n"
     ]
    }
   ],
   "source": [
    "# fit combined models to data\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "predict = model.fit(train_data, train_labels,\n",
    "             epochs=epochs,\n",
    "             batch_size=batch_size,\n",
    "             validation_data=(validation_data, validation_labels), callbacks=[checkpointer], verbose =2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x000000000F7C4EB8>\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "print(predict.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(predict.history.keys())\n",
    "plt.plot(predict.history['acc'])\n",
    "plt.plot(predict.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best trained weights\n",
    "\n",
    "model.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 333us/step\n",
      "\n",
      " Test accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#use model predict to create bottleneck weights from VGG16 & save to .npy file\n",
    "\n",
    "#test_labels = model.evaluate_generator(generator, steps=len(generator), workers=1, use_multiprocessing=False)\n",
    "\n",
    "#probabilities = model.predict_generator(generator, 6)\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#y_true = np.array([0] * 1000 + [1] * 1000)\n",
    "#y_pred = probabilities > 0.5\n",
    "\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "score = model.evaluate(test_data, test_labels, verbose=1)\n",
    "print('\\n', 'Test accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
